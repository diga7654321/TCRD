import json
import time
import os
import networkx as nx
import pandas as pd
from openai import OpenAI
from tqdm import tqdm  


OPENAI_KEY = "sk-V9He0b5b0372b2316ba5786853240bc2d8b56c05c28fcEjA"
OPENAI_BASE = "https://api.gptsapi.net/v1"
INPUT_FILE = "../../Datasets/Weibo/filtered_weibo.json"
# INPUT_FILE = "../../Datasets/filtered_pheme.json"

MODEL = "gpt-4o-mini"


client = OpenAI(api_key=OPENAI_KEY, base_url=OPENAI_BASE)


def load_json(path):
    return json.load(open(path, 'r', encoding='utf-8')) if os.path.exists(path) else {}

def save_json(data, path):
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def get_trust_scores_batch(news_content, comment_list, cache, raw_output, news_id, model=MODEL, retries=3):
    news_id_str = str(news_id)


    if news_id_str in raw_output:
        print(f"üîÅ  {news_id_str}")
        existing_result = raw_output[news_id_str]
        scores = {}

        if existing_result == "":
            cache[news_id_str] = {}
            return {}

        lines = [line for line in existing_result.strip().split("\n") if ":" in line]
        for line in lines:
            parts = line.split(":")
            if len(parts) == 2:
                cid, val = parts
                try:
                    idx = int(cid.strip().lower().replace("comment_", ""))
                    score = float(val.strip())
                    scores[str(idx)] = max(0.0, min(1.0, score))
                except:
                    continue

        cache[news_id_str] = scores
        return scores


    if not comment_list:
        raw_output[news_id_str] = ""
        cache[news_id_str] = {}
        return {}

    comment_input = "\n".join([f"comment_{i+1}: {comment}" for i, comment in enumerate(comment_list)])
    prompt = f"""
   You are an expert in modeling user behavior on social media.
   A piece of news has now been officially debunked by a trusted organization and confirmed to be false. Below are comments that users made about the news *before* it was debunked.
   Your task is to simulate how each user would react *after* learning that a trusted authority has publicly stated the news is false.    For a simulated response, a trust score is assigned to the response, indicating how much the simulated user's response is trusted for the news.
   For each original comment:
   - Think about whether the user would still post that comment again, under the new understanding.
   - If their opinion or behavior would change, reflect that in your rating.
   Returns a **Trust Score** between 0 and 1 for each comment:
   - 1 = The user fully trusts the news.
   - 0 = User does not trust the news at all.
   - 0.5 = The user may still be unsure or react more cautiously.
   Here are the original user comments:{comment_input}
   
   Please return your output in this format:
   comment_1: 0.85  
   comment_2: 0.10  
   comment_3: 0.50  
    ...
    """.strip()

    for attempt in range(retries):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2
            )
            result = response.choices[0].message.content.strip()
            raw_output[news_id_str] = result  

            scores = {}
            lines = [line for line in result.split("\n") if ":" in line]
            for line in lines:
                parts = line.split(":")
                if len(parts) == 2:
                    cid, val = parts
                    try:
                        idx = int(cid.strip().lower().replace("comment_", ""))
                        score = float(val.strip())
                        scores[str(idx)] = max(0.0, min(1.0, score))
                    except:
                        continue

            cache[news_id_str] = scores
            return scores

        except Exception as e:
            print(f"[Retry {attempt + 1}] LLM batch failed for news {news_id}: {e}")
            time.sleep(3)

        # fallback
    raw_output[news_id_str] = "FAILED"
    cache[news_id_str] = {str(i): 0.5 for i in range(len(comment_list))}
    return cache[news_id_str]


def build_counter_trust_graph_from_json_with_llm(json_path, cache_path, llm_output_path):
    data = load_json(json_path)
    cache = load_json(cache_path)
    llm_output = load_json(llm_output_path)
    trust_graphs = {}
    edge_records = []

    for idx, (news_id, entry) in enumerate(tqdm(sorted(data.items(), key=lambda x: int(x[0])), desc="üöß "),
                                           start=1):
        news_id_str = str(news_id)
        content = entry.get("content", "")
        comments = entry.get("comments", [])
        if not isinstance(comments, list):
            comments = []

        comments = [c.strip() for c in comments if isinstance(c, str) and c.strip()][:10]

        if news_id_str in cache and news_id_str in llm_output:
            scores = cache[news_id_str]
        else:
            scores = get_trust_scores_batch(content, comments, cache, llm_output, news_id)


        G = nx.DiGraph()
        news_node = f"news_{news_id}"
        G.add_node(news_node, type="news", content=content)

        for i, comment in enumerate(comments):
            user_node = f"user_{news_id}_{i}"
            G.add_node(user_node, type="user", comment=comment)
            weight = scores.get(str(i), 0.5)
            G.add_edge(user_node, news_node, weight=weight, comment=comment)

            edge_records.append({
                "news_id": news_id,
                "from": user_node,
                "to": news_node,
                "comment": comment,
                "weight": weight
            })

        trust_graphs[news_id_str] = G


        save_json(dict(sorted(cache.items(), key=lambda x: int(x[0]))), cache_path)
        save_json(dict(sorted(llm_output.items(), key=lambda x: int(x[0]))), llm_output_path)

    edge_df = pd.DataFrame(edge_records)
    return trust_graphs, edge_df

